importlib torch
import json
import os
import faiss
import pandas as pd
import numpy as np
import importlib.util
import sys
from dotenv import load_dotenv
load_dotenv()


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Paths to saved files
index_path = "/workspace/FCAPS/RAG/logs.index"
metadata_path = "/workspace/FCAPS/RAG/metadata_with_clusters.csv"

# Load the FAISS index and metadata
index = faiss.read_index(index_path)
metadata_df = pd.read_csv(metadata_path)

# Add RAG path
rag_path = "/workspace/FCAPS/RAG"
if rag_path not in sys.path:
    sys.path.append(rag_path)
print("RAG path added:", rag_path)

# Load llm_agent.py
file_path = os.path.join(rag_path, "llm_agent.py")
spec = importlib.util.spec_from_file_location("llm_agent", file_path)
llm_agent = importlib.util.module_from_spec(spec)
spec.loader.exec_module(llm_agent)

# Define the Mistral function
def run_mistral(query, results):
    """
    Generate a response from the Mistral model based on query and RAG results.
    :param query: The query string to process.
    :param results: The retrieved logs and data.
    :return: The response generated by the model.
    """
    prompt = """
    [INST]Given a dataset of Linux logs, we aim to detect a higher concentration of authentication failures and identify their patterns. We have retrieved multiple log entries where authentication failures occurred, all originating from the same IP address (163.27.187.39).

    Step-by-Step Analysis:
    1.Extract Key Information: Identify repeated patterns in authentication failure logs.
    2. Detect Anomalies: Determine if failures originate from a single IP or multiple sources.
    3. Analyze Frequency: Assess whether failures occur in bursts or continuously over time.
    4. Identify Possible Causes: Consider reasons such as brute-force attacks, expired credentials, or network issues.
    5. Suggest Actions: Recommend security measures, such as blocking the IP, enabling CAPTCHA, or monitoring failed attempts.
    Task:
    Based on the given authentication failure logs, analyze the pattern of failures and explain whether this suggests an attack or a misconfiguration. Provide reasoning for your conclusion.[/INST]
    """

    for dataset, log_index, similarity, log_content in results:
        prompt += f"- **Dataset**: {dataset}, **Log Index**: {log_index}, **Similarity**: {similarity:.4f}\n"
        prompt += f"  **Log Content**: {log_content}\n\n"

    prompt += "[/INST]"

    tokenizer.add_special_tokens({'pad_token': '[PAD]'})

    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, padding=True, max_length=512)
    input_ids = inputs['input_ids'].to(device)
    attention_mask = (input_ids != tokenizer.pad_token_id).long()

    outputs = model.generate(input_ids, attention_mask=attention_mask, max_length=2048, num_return_sequences=1, do_sample=True, temperature=1.2)
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)

    # Define paths for saving response
    response_path = "/workspace/FCAPS/responses/response.json"
    markdown_path = "/workspace/FCAPS/responses/response.md"

    # Load existing responses if any
    if os.path.exists(response_path):
        with open(response_path, "r") as f:
            previous_responses = json.load(f)
    else:
        previous_responses = []

    # Prepare new response data
    response_data = {
        "query": query,
        "response": response,
        "logs": [
            {
                "dataset": dataset,
                "log_index": int(log_index),
                "similarity": float(similarity),
                "log_content": log_content
            }
            for dataset, log_index, similarity, log_content in results
        ]
    }

    # Append new response data
    previous_responses.append(response_data)

    # Save the updated responses to JSON and markdown
    with open(response_path, "w") as f:
        json.dump(previous_responses, f, indent=4)

    with open(markdown_path, "a") as f:
        f.write(f"\n\n---\n# Response for Query: {query}\n")
        f.write(f"### Logs Used:\n")
        for entry in response_data["logs"]:
            f.write(f"- Dataset: {entry['dataset']}, Log Index: {entry['log_index']}, Similarity: {entry['similarity']:.4f}\n")
            f.write(f"  **Log Content**: {entry['log_content']}\n\n")
        f.write(f"\n### Model Response:\n{response}\n")

    print(f"Response saved successfully!\n- JSON: {response_path}\n- Markdown: {markdown_path}")

    return response  # Return the generated response
